from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import random
import re
import os
import django

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')
django.setup()

from main_app.models import LianJiaHouse


class SeleniumLianJiaSpider:
    def __init__(self):
        # Chromeé€‰é¡¹è®¾ç½®
        self.options = Options()
        self.options.add_argument(
            '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        self.options.add_argument('--disable-blink-features=AutomationControlled')
        self.options.add_experimental_option("excludeSwitches", ["enable-automation"])
        self.options.add_experimental_option('useAutomationExtension', False)
        self.options.add_argument('--no-sandbox')
        self.options.add_argument('--disable-dev-shm-usage')

        # åˆå§‹åŒ–æµè§ˆå™¨
        self.driver = webdriver.Chrome(options=self.options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

        # è®¾ç½®ç­‰å¾…æ—¶é—´
        self.wait = WebDriverWait(self.driver, 10)

    def crawl_district(self, district, pages=2):
        """çˆ¬å–æŒ‡å®šåŒºåŸŸçš„æ•°æ®"""
        print(f"ğŸ“ å¼€å§‹çˆ¬å– {district} åŒºåŸŸ...")

        all_houses = []

        for page in range(1, pages + 1):
            print(f"ğŸ“„ æ­£åœ¨çˆ¬å–ç¬¬ {page} é¡µ...")

            url = f"https://bj.lianjia.com/ershoufang/{district}/pg{page}/"
            print(f"ğŸŒ è®¿é—®: {url}")

            try:
                self.driver.get(url)

                # ç­‰å¾…é¡µé¢åŠ è½½
                time.sleep(random.uniform(3, 5))

                # æ£€æŸ¥æ˜¯å¦æœ‰éªŒè¯ç æˆ–ç™»å½•é¡µé¢
                current_url = self.driver.current_url
                if "verify" in current_url or "login" in current_url or "captcha" in current_url:
                    print("ğŸš« é‡åˆ°éªŒè¯ç æˆ–ç™»å½•é¡µé¢ï¼Œéœ€è¦æ‰‹åŠ¨å¤„ç†")
                    input("è¯·æ‰‹åŠ¨å¤„ç†éªŒè¯ç /ç™»å½•ï¼Œç„¶åæŒ‰å›è½¦ç»§ç»­...")

                # ç­‰å¾…æˆ¿æºåˆ—è¡¨åŠ è½½
                try:
                    self.wait.until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, ".sellListContent li, .content__list--item"))
                    )
                except TimeoutException:
                    print("âŒ é¡µé¢åŠ è½½è¶…æ—¶ï¼Œæœªæ‰¾åˆ°æˆ¿æºåˆ—è¡¨")
                    continue

                # è·å–é¡µé¢æºç å¹¶è§£æ
                html = self.driver.page_source
                houses = self.parse_page(html, district)
                all_houses.extend(houses)

                print(f"âœ… ç¬¬ {page} é¡µè·å–åˆ° {len(houses)} ä¸ªæˆ¿æº")

                # éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«å°
                time.sleep(random.uniform(2, 4))

            except Exception as e:
                print(f"âŒ çˆ¬å–ç¬¬ {page} é¡µå¤±è´¥: {e}")
                continue

        return all_houses

    def parse_page(self, html, district):
        """è§£æé¡µé¢å†…å®¹"""
        from bs4 import BeautifulSoup

        soup = BeautifulSoup(html, 'html.parser')
        houses = []

        # æŸ¥æ‰¾æˆ¿æºåˆ—è¡¨
        house_list = soup.select('.sellListContent li, .clear .LOGCLICKDATA, [class*="info clear"]')

        if not house_list:
            print("âŒ æœªæ‰¾åˆ°æˆ¿æºåˆ—è¡¨")
            # ä¿å­˜é¡µé¢ç”¨äºè°ƒè¯•
            with open(f"selenium_debug_{district}.html", "w", encoding="utf-8") as f:
                f.write(html)
            print(f"ğŸ’¾ è°ƒè¯•é¡µé¢å·²ä¿å­˜: selenium_debug_{district}.html")
            return houses

        print(f"ğŸ“Š æ‰¾åˆ° {len(house_list)} ä¸ªæˆ¿æº")

        for i, item in enumerate(house_list):
            try:
                print(f"  è§£æç¬¬ {i + 1} ä¸ªæˆ¿æº...")
                house_data = self.parse_house_item(item, district)
                if house_data:
                    houses.append(house_data)
                    print(f"  âœ… è§£ææˆåŠŸ: {house_data['title'][:20]}...")
            except Exception as e:
                print(f"  âŒ è§£æå¤±è´¥: {e}")

        return houses

    def parse_house_item(self, item, district):
        """è§£æå•ä¸ªæˆ¿æºä¿¡æ¯"""
        try:
            # æ ‡é¢˜
            title_elem = item.select_one('.title a, .houseInfo a, a[href*="/ershoufang/"]')
            if not title_elem:
                return None

            title = title_elem.get_text(strip=True)
            detail_url = title_elem.get('href', '')
            if detail_url and not detail_url.startswith('http'):
                detail_url = 'https://bj.lianjia.com' + detail_url

            # æ€»ä»·
            total_price = 0
            price_elem = item.select_one('.totalPrice, .priceInfo .total, .total-price')
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                match = re.search(r'(\d+\.?\d*)', price_text)
                if match:
                    total_price = float(match.group(1))

            # å•ä»·
            unit_price = 0
            unit_price_elem = item.select_one('.unitPrice, .priceInfo .unit, .unit-price')
            if unit_price_elem:
                unit_text = unit_price_elem.get_text(strip=True)
                match = re.search(r'(\d+)', unit_text)
                if match:
                    unit_price = float(match.group(1))

            # å°åŒº
            xiaoqu = 'æœªçŸ¥'
            position_elem = item.select_one('.positionInfo a, .houseInfo .area a, .communityName a')
            if position_elem:
                xiaoqu = position_elem.get_text(strip=True)

            # æˆ¿å±‹ä¿¡æ¯
            house_info = ''
            house_info_elem = item.select_one('.houseInfo, .info-col, .house-info')
            if house_info_elem:
                house_info = house_info_elem.get_text(strip=True)

            # è§£æè¯¦ç»†ä¿¡æ¯
            layout, area, floor_info, orientation = self.parse_house_info(house_info)

            # åŒºåŸŸæ˜ å°„
            districts = {
                'chaoyang': 'æœé˜³', 'haidian': 'æµ·æ·€', 'dongcheng': 'ä¸œåŸ',
                'xicheng': 'è¥¿åŸ', 'fengtai': 'ä¸°å°', 'shijingshan': 'çŸ³æ™¯å±±'
            }
            district_cn = districts.get(district, district)

            # é¢ç§¯
            area_value = 0
            if area and area != 'æœªçŸ¥':
                match = re.search(r'(\d+\.?\d*)', area)
                if match:
                    area_value = float(match.group(1))

            return {
                'title': title,
                'total_price': total_price,
                'unit_price': unit_price,
                'district': district_cn,
                'area': area_value,
                'layout': layout,
                'xiaoqu': xiaoqu,
                'floor': floor_info,
                'orientation': orientation,
                'description': house_info,
                'source_url': detail_url,
                'city': 'åŒ—äº¬',
            }

        except Exception as e:
            print(f"è§£ææˆ¿æºå¤±è´¥: {e}")
            return None

    def parse_house_info(self, house_info):
        """è§£ææˆ¿å±‹ä¿¡æ¯"""
        layout = area = floor_info = orientation = 'æœªçŸ¥'
        if house_info:
            parts = [part.strip() for part in house_info.split('|') if part.strip()]
            if len(parts) >= 4:
                layout, area, floor_info, orientation = parts[:4]
        return layout, area, floor_info, orientation

    def save_houses(self, houses):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        saved_count = 0
        for house_data in houses:
            try:
                # é¿å…é‡å¤
                existing = LianJiaHouse.objects.filter(
                    title=house_data['title'],
                    source_url=house_data['source_url']
                ).exists()

                if not existing:
                    LianJiaHouse.objects.create(**house_data)
                    saved_count += 1
                    print(f"ğŸ’¾ ä¿å­˜: {house_data['title'][:30]}... - {house_data['total_price']}ä¸‡")
                else:
                    print(f"â­ï¸ å·²å­˜åœ¨: {house_data['title'][:30]}...")

            except Exception as e:
                print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

        return saved_count

    def start_crawl(self, max_pages_per_district=2):
        """å¼€å§‹çˆ¬è™«"""
        print("ğŸš€ å¼€å§‹Seleniumçˆ¬å–é“¾å®¶æ•°æ®...")
        print("=" * 50)

        count_before = LianJiaHouse.objects.count()
        print(f"ğŸ“Š çˆ¬å–å‰æ•°æ®åº“æœ‰ {count_before} æ¡æ•°æ®")

        districts = {
            'chaoyang': 'æœé˜³',
            'haidian': 'æµ·æ·€',
            'dongcheng': 'ä¸œåŸ',
            'xicheng': 'è¥¿åŸ'
        }

        total_saved = 0

        try:
            for district_en, district_cn in districts.items():
                print(f"\nğŸ“ å¼€å§‹çˆ¬å– {district_cn} åŒºåŸŸ...")

                houses = self.crawl_district(district_en, max_pages_per_district)
                saved_count = self.save_houses(houses)
                total_saved += saved_count

                print(f"ğŸ“Š {district_cn} åŒºåŸŸ: è·å– {len(houses)} æ¡ï¼Œæ–°å¢ {saved_count} æ¡")

        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")

        finally:
            # å…³é—­æµè§ˆå™¨
            self.driver.quit()
            print("ğŸ”š æµè§ˆå™¨å·²å…³é—­")

        count_after = LianJiaHouse.objects.count()
        print(f"\n" + "=" * 50)
        print(f"ğŸ‰ Seleniumçˆ¬å–å®Œæˆï¼")
        print(f"ğŸ“ˆ æ–°å¢ {total_saved} æ¡æ•°æ®")
        print(f"ğŸ“Š ç°åœ¨å…±æœ‰ {count_after} æ¡æ•°æ®")

        return total_saved